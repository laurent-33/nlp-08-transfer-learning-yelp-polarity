{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base packages\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Import ML packages\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read train/test datasets\n",
    "Create a function to read train and test datasets with follow actions:\n",
    "- Have a look at readme.txt to get more information about the datasets\n",
    "- Columns should be renamed to 'rate' and 'text'\n",
    "- Take a random sample of 5000 records for training and test datasets\n",
    "- Positive labels should be mapped to 0 (instead of 2 in the initial dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131923</th>\n",
       "      <td>2</td>\n",
       "      <td>So, up until tonight, I've primarily used Yelp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452109</th>\n",
       "      <td>1</td>\n",
       "      <td>This Pita Jungle had some blemishes... the pit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549634</th>\n",
       "      <td>1</td>\n",
       "      <td>The only reason this place is worthy of one st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491197</th>\n",
       "      <td>2</td>\n",
       "      <td>Good bar.  Good location. The service was quic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321865</th>\n",
       "      <td>2</td>\n",
       "      <td>I am remiss in not writing my review of our di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rate                                               text\n",
       "131923     2  So, up until tonight, I've primarily used Yelp...\n",
       "452109     1  This Pita Jungle had some blemishes... the pit...\n",
       "549634     1  The only reason this place is worthy of one st...\n",
       "491197     2  Good bar.  Good location. The service was quic...\n",
       "321865     2  I am remiss in not writing my review of our di..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_format_dataset(dataset_path):\n",
    "    fulldata = pd.read_csv(dataset_path, header=0, names=['rate', 'text'])\n",
    "    \n",
    "    return fulldata.sample(5000)\n",
    "\n",
    "train_dataset_path = './Data/train.csv'\n",
    "test_dataset_path = './Data/test.csv'\n",
    "train_data = read_format_dataset(train_dataset_path)\n",
    "test_data = read_format_dataset(test_dataset_path)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2)\n",
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training pipeline\n",
    "Our pipeline will use:\n",
    "- TFIDF to vectorize our text\n",
    "- RandomForest on top of these features\n",
    "\n",
    "You should first build this sklearn pipeline and use RandomizedSearchCV to get the best parameters for your pipeline. As our training dataset is small, you would probably increase the number of cross validations. Use accuracy as target metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline definition\n",
    "tfidf = TfidfVectorizer(\n",
    "    stop_words=None,\n",
    "    ngram_range=(1, 1),\n",
    "    max_df=1.0,\n",
    "    min_df=1,\n",
    "    max_features=None,\n",
    "    norm='l2',\n",
    "    sublinear_tf=False\n",
    ")\n",
    "rfc = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight=None,\n",
    "    ccp_alpha=0.0,\n",
    "    max_samples=None\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('traitement', tfidf),\n",
    "    ('modele', rfc)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'traitement__stop_words': [None, 'english'], 'modele__n_estimators': [50, 100, 200]}\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'traitement__stop_words': [None, 'english'],\n",
    "    #'traitement__norm': ['l1', 'l2'],\n",
    "    #'traitement__max_features': [None, 100],\n",
    "    #'traitement__sublinear_tf': [False, True],\n",
    "    'modele__n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   34.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('traitement',\n",
       "                                              TfidfVectorizer(analyzer='word',\n",
       "                                                              binary=False,\n",
       "                                                              decode_error='strict',\n",
       "                                                              dtype=<class 'numpy.float64'>,\n",
       "                                                              encoding='utf-8',\n",
       "                                                              input='content',\n",
       "                                                              lowercase=True,\n",
       "                                                              max_df=1.0,\n",
       "                                                              max_features=None,\n",
       "                                                              min_df=1,\n",
       "                                                              ngram_range=(1,\n",
       "                                                                           1),\n",
       "                                                              norm='l2',\n",
       "                                                              preprocessor=None,\n",
       "                                                              smooth_idf=True,\n",
       "                                                              stop_words=...\n",
       "                                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                                     n_estimators=100,\n",
       "                                                                     n_jobs=-1,\n",
       "                                                                     oob_score=False,\n",
       "                                                                     random_state=15,\n",
       "                                                                     verbose=0,\n",
       "                                                                     warm_start=False))],\n",
       "                                      verbose=False),\n",
       "                   iid='deprecated', n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'modele__n_estimators': [50, 100, 200],\n",
       "                                        'traitement__stop_words': [None,\n",
       "                                                                   'english']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=15, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=5,\n",
    "    n_jobs=-1,\n",
    "    cv=None,\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(train_data.loc[:, 'text'], train_data.loc[:, 'rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on test dataset\n",
    "Compute the accuracy for our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'traitement__stop_words': 'english', 'modele__n_estimators': 200}\n",
      "0.861\n"
     ]
    }
   ],
   "source": [
    "best_rfc = random_search.best_params_\n",
    "print(best_rfc)\n",
    "y_pred = random_search.predict(test_data.loc[:, 'text'])\n",
    "acc = accuracy_score(test_data.loc[:, 'rate'], y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
